import asyncio
import logging
import aiohttp
from aiogram import Bot, Dispatcher, types, F
from aiogram.enums import ParseMode
from aiogram.filters import Command
from aiogram.utils.keyboard import ReplyKeyboardBuilder
import os
from openai import OpenAI

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# API endpoints
MISTRAL_API_URL = "https://api.mistral.ai/v1/chat/completions"

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
MISTRAL_API_KEY = os.getenv("MISTRAL_API_KEY", "o4HcmjBOPlElwwGO3r3OlhsRY4gCDfrt")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-aitunnel-Bm73SZY1JAzXh4e5rzlhcY6cmvqb2UV0")
LLAMA_API_KEY = os.getenv("LLAMA_API_KEY", "sk-aitunnel-Bm73SZY1JAzXh4e5rzlhcY6cmvqb2UV0")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "sk-aitunnel-Bm73SZY1JAzXh4e5rzlhcY6cmvqb2UV0")
IMAGE_API_KEY = os.getenv("IMAGE_API_KEY", "sk-aitunnel-Bm73SZY1JAzXh4e5rzlhcY6cmvqb2UV")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
BOT_TOKEN = "7707968884:AAFhHJ9WA9NwOZ1Bdy5zTuj0riXxuDq9_g0"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π
user_states = {}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è DeepSeek, Llama, Gemini –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
deepseek_client = OpenAI(
    api_key=DEEPSEEK_API_KEY,
    base_url="https://api.aitunnel.ru/v1/",
)

llama_client = OpenAI(
    api_key=LLAMA_API_KEY,
    base_url="https://api.aitunnel.ru/v1/",
)

gemini_client = OpenAI(
    api_key=GEMINI_API_KEY,
    base_url="https://api.aitunnel.ru/v1/",
)

image_client = OpenAI(
    api_key=IMAGE_API_KEY,
    base_url="https://api.aitunnel.ru/v1/",
)

def get_model_keyboard():
    builder = ReplyKeyboardBuilder()
    builder.add(types.KeyboardButton(text="ü¶Ö Mistral"))
    builder.add(types.KeyboardButton(text="üß† DeepSeek"))
    builder.add(types.KeyboardButton(text="ü¶ô Llama"))
    builder.add(types.KeyboardButton(text="üåü Gemini"))
    builder.add(types.KeyboardButton(text="üñºÔ∏è Generate Image"))
    builder.adjust(2)
    return builder.as_markup(resize_keyboard=True)

async def call_mistral_api(prompt: str) -> str:
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": "mistral-small-latest",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 2000
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                    MISTRAL_API_URL,
                    headers=headers,
                    json=payload,
                    timeout=30
            ) as resp:
                resp.raise_for_status()
                data = await resp.json()
                return data['choices'][0]['message']['content']
    except Exception as e:
        logger.error(f"Mistral API error: {str(e)}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Mistral API"

async def call_deepseek_api(prompt: str) -> str:
    try:
        chat_result = deepseek_client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="deepseek-chat",
            max_tokens=2000,
        )
        return chat_result.choices[0].message.content
    except Exception as e:
        logger.error(f"DeepSeek API error: {str(e)}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ DeepSeek API"

async def call_llama_api(prompt: str) -> str:
    try:
        chat_result = llama_client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.2",
            max_tokens=2000,
        )
        return chat_result.choices[0].message.content
    except Exception as e:
        logger.error(f"Llama API error: {str(e)}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Llama API"

async def call_gemini_api(prompt: str) -> str:
    try:
        chat_result = gemini_client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="gemini-flash-1.5-8b",
            max_tokens=2000,
        )
        return chat_result.choices[0].message.content
    except Exception as e:
        logger.error(f"Gemini API error: {str(e)}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Gemini API"

async def generate_image(prompt: str, size: str = "1024x1024") -> str:
    try:
        image_res = image_client.images.generate(
            model="dall-e-2",
            size=size,
            quality="standard",
            prompt=prompt
        )
        return image_res.data[0].url
    except Exception as e:
        logger.error(f"Image generation error: {str(e)}")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"

@dp.message(Command("start", "help"))
async def cmd_start(message: types.Message):
    user_id = message.from_user.id
    user_states[user_id] = "mistral"

    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —á–µ—Ç—ã—Ä–µ—Ö AI-–º–æ–¥–µ–ª–µ–π –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:\n\n"
        "ü¶Ö <b>Mistral</b> - –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏\n"
        "üß† <b>DeepSeek v3</b> - –±—ã—Å—Ç—Ä–∞—è –∏ –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –º–æ–¥–µ–ª—å\n"
        "ü¶ô <b>Llama 3.2</b> - –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n"
        "üåü <b>Gemini 1.5</b> - –Ω–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é\n"
        "üñºÔ∏è <b>Generate Image</b> - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n\n"
        "–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏—é:",
        reply_markup=get_model_keyboard(),
        parse_mode=ParseMode.HTML
    )

@dp.message(F.text == "ü¶Ö Mistral")
async def select_mistral(message: types.Message):
    user_id = message.from_user.id
    user_states[user_id] = "mistral"
    await message.answer(
        "‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: <b>Mistral</b>",
        reply_markup=get_model_keyboard(),
        parse_mode=ParseMode.HTML
    )

@dp.message(F.text == "üß† DeepSeek")
async def select_deepseek(message: types.Message):
    user_id = message.from_user.id
    user_states[user_id] = "deepseek"
    await message.answer(
        "‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: <b>DeepSeek</b>",
        reply_markup=get_model_keyboard(),
        parse_mode=ParseMode.HTML
    )

@dp.message(F.text == "ü¶ô Llama")
async def select_llama(message: types.Message):
    user_id = message.from_user.id
    user_states[user_id] = "llama"
    await message.answer(
        "‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: <b>Llama</b>",
        reply_markup=get_model_keyboard(),
        parse_mode=ParseMode.HTML
    )

@dp.message(F.text == "üåü Gemini")
async def select_gemini(message: types.Message):
    user_id = message.from_user.id
    user_states[user_id] = "gemini"
    await message.answer(
        "‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: <b>Gemini</b>",
        reply_markup=get_model_keyboard(),
        parse_mode=ParseMode.HTML
    )

@dp.message(F.text == "üñºÔ∏è Generate Image")
async def select_generate_image(message: types.Message):
    user_id = message.from_user.id
    user_states[user_id] = "generate_image"
    await message.answer(
        "‚úÖ –í—ã–±—Ä–∞–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è: <b>Generate Image</b>\n\n"
        "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–º–µ—Ä:\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã: 256x256, 512x512, 1024x1024",
        reply_markup=get_model_keyboard(),
        parse_mode=ParseMode.HTML
    )

@dp.message()
async def handle_message(message: types.Message):
    if message.text.startswith('/'):
        return

    user_id = message.from_user.id
    if user_id not in user_states:
        user_states[user_id] = "mistral"

    model = user_states[user_id]
    await bot.send_chat_action(message.chat.id, "typing")

    try:
        if model == "mistral":
            response = await call_mistral_api(message.text)
            prefix = "ü¶Ö <b>Mistral</b>:\n\n"
        elif model == "llama":
            response = await call_llama_api(message.text)
            prefix = "ü¶ô <b>Llama</b>:\n\n"
        elif model == "gemini":
            response = await call_gemini_api(message.text)
            prefix = "üåü <b>Gemini</b>:\n\n"
        elif model == "generate_image":
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä"
            parts = message.text.rsplit(' ', 1)
            if len(parts) != 2 or parts[1] not in ["256x256", "512x512", "1024x1024"]:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            prompt, size = parts
            response = await generate_image(prompt, size)
            prefix = "üñºÔ∏è <b>Generate Image</b>:\n\n"
        else:
            response = await call_deepseek_api(message.text)
            prefix = "üß† <b>DeepSeek</b>:\n\n"

        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏
        max_length = 4000
        for i in range(0, len(response), max_length):
            part = response[i:i+max_length]
            await message.answer(
                prefix + part,
                parse_mode=ParseMode.HTML
            )

    except Exception as e:
        logger.error(f"Error processing message: {str(e)}", exc_info=True)
        await message.answer(
            "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞",
            parse_mode=ParseMode.HTML
        )

async def main():
    await bot.delete_webhook(drop_pending_updates=True)
    try:
        await dp.start_polling(bot)
    finally:
        await bot.session.close()

if __name__ == "__main__":
    logger.info("Starting bot...")
    asyncio.run(main())
